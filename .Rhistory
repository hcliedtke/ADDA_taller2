# remove all NHCs below 10 or NIFs "bloqueado"
filter(!(as.numeric(NHC)<10 & !is.na(NHC)),
!(str_detect(tolower(NIF), "bloqueado") & !is.na(NIF))) %>%
# remove rows that are all NA
filter(if_any(-c(NHC,NIF, sanityID, TipoVisita, FechaVisita,Responsable,ResponsableAbrev), ~ !is.na(.))) %>%
# rename all variables
rename(lookup %>%
select(Metakey, Variable) %>%
drop_na() %>%
deframe()) %>%
# trim white spaces at start and end of all string vectors
mutate(across(where(is.character), str_trim)) %>%
# remove all line breaks from strings
mutate(across(where(is.character), ~str_replace_all(.x,pattern = "\r\n",replacement = " "))) %>%
mutate(across(where(is.character), ~str_replace_all(.x,pattern = "\\s+",replacement = " "))) %>%
# sort by date and NHC
arrange(metaFecha, hce) %>%
# add patient ID
left_join(users %>%
select(ID, hce) %>%
drop_na()) %>%
## add responsable ID
left_join(responsables %>%
select(ID, Responsable,nombre) %>%
rename(respID=ID,
vispsicResp=Responsable) %>%
drop_na() %>%
distinct_all()) %>%
mutate(vispsicResp=str_to_title(nombre)) %>%
# duplicate NIF
mutate(NIF=metaPaciente,
metaPaciente=ID) %>%
# change quote types in vispsicObs
mutate(vispsicObs = str_replace_all(vispsicObs, "\"","\'"))
####
## sanity checks
####
# which records were deleted?
dat_deleted<-dat %>%
filter(!row_number() %in% dat_clean$sanityID)
dat_deleted
#do all entries have a pat ID?
dat_clean %>%
filter(is.na(ID))
#do all entries have NIFs or hces?
dat_clean %>%
filter(is.na(NIF) & is.na(hce))
##################################
# helper functions
##################################
# write functions to extract information from data set in a format that is required
##################################
# make wp_posts and wp_postmeta
##################################
## load empty wp templates
wp_posts_in<-read_csv2("../../templates/wp_posts.csv")
wp_postmeta_in<-read_csv2("../../templates/wp_postmeta.csv")
# remove all previous entries for the examples
wp_posts_in<-wp_posts_in[0,]
wp_postmeta_in<-wp_postmeta_in[0,]
## check last post number from previous post type
last_post<-read_csv2("../vismedicas/out/wp_posts.csv", col_names = F)
last_post<-max(last_post[,1])
last_postmeta<-read_csv2("../vismedicas/out/wp_postmeta.csv", col_names = F)
last_postmeta<-max(last_postmeta[,1])
#####
# create posts
#####
# make wp_post
posts<-dat_clean %>%
mutate(
user_id = ID, # check this!!
ID = row_number() + last_post, # DANGER!!! SETTING POST ID'S MANUALLY!!!
post_author = respID,
post_date = format(metaFecha, "%Y-%m-%d %H:%M:%S"),
post_date_gmt = format(with_tz(post_date, tzone="GMT"), "%Y-%m-%d %H:%M:%S"),
post_content = "Visita Psicológica (durante Hospitalización)",
post_title = paste0("us-", user_id, "-tr-",as.numeric(hce),format(metaFecha, "%Y%m%d"), "-vispsicolog"),
post_excerpt = NA,
post_status = "publish",
comment_status = "closed",
ping_status = "closed",
post_password = NA,
post_name = post_title,
to_ping = NA,
pinged = NA,
post_modified = format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
post_modified_gmt = format(with_tz(post_modified, tzone="GMT"), "%Y-%m-%d %H:%M:%S"),
post_content_filtered = NA,
post_parent = NA,
guid = paste0("https://silocreativo.win/react/vispsicolog/",post_name),
menu_order = 0,
post_type = "vispsicolog",
post_mime_type = 0,
comment_count = 0
) %>%
select(colnames(wp_posts_in))
### incorporate into wp_posts
wp_posts<-wp_posts_in %>%
mutate_all(as.character) %>%
bind_rows(posts %>% mutate_all(as.character))
######
# create posts metadata
######
postmeta<-dat_clean %>%
# select only postmeta variables
select(all_of(lookup %>%
filter(Tabla=="wp_postmeta") %>%
pull(Metakey))) %>%
# add post numbers (row numbers +100 ) DANGER!!!!
mutate(post_id=row_number() + last_post) %>%
# reinforce date format
mutate(metaFecha= format(metaFecha, "%Y-%m%-%d")) %>%
# convert all to character %>%
mutate_all(as.character) %>%
# pivot
pivot_longer(-post_id, names_to="meta_key" , values_to = "meta_value") %>%
drop_na(meta_value)
### incorporate into wp_postmeta
wp_postmeta <- wp_postmeta_in %>%
mutate_all(as.character) %>%
bind_rows(postmeta) %>%
# overwrite meta id ## DANGER!!!
mutate(meta_id=row_number() + last_postmeta)
## export
write_csv2(wp_posts %>% mutate_all(as.character), "./out/wp_posts.csv", na="", quote="all", col_names = F)
write_csv2(wp_postmeta %>% mutate_all(as.character), "./out/wp_postmeta.csv", na="", quote="all", col_names=F)
setwd("~/Documents/upwork/tavad/migrate salus/posts/")
scr<-list.files("./", recursive = T, pattern="import_.*\\.R", full.names = T)
scr
### execute all post import  and then combine outputs
library(tidyverse)
setwd("~/Documents/upwork/tavad/migrate salus/posts/")
scr<-list.files("./", recursive = T, pattern="import_.*\\.R", full.names = T)
scr
# past working directory
scr<-paste0(getwd(), str_remove(scr,"./"))
source(scr[2])
#run
lapply(X=scr, FUN=source)
### execute all post import  and then combine outputs
library(tidyverse)
setwd("~/Documents/upwork/tavad/migrate salus/posts/")
scr<-list.files("./", recursive = T, pattern="import_.*\\.R", full.names = T)
scr
# past working directory
scr<-paste0(getwd(), str_remove(scr,"./"))
source(scr[2])
#run
lapply(X=scr, FUN=source)
#############
############# combine all posts
#############
# post
setwd("~/Documents/upwork/tavad/migrate salus/posts/")
post_files<-list.files("./",recursive = T, pattern = "wp_posts", full.names = T)
post_files
# check creating time
file.info(post_files)$mtime
# combine
all_posts<-list()
for(i in 1:length(post_files)){
all_posts[[i]]<-read_csv2(file = post_files[i], col_names = F, col_types = cols(.default = "c"))
}
sapply(all_posts, ncol)
all_posts_df<-bind_rows(all_posts)
# export
write_csv2(all_posts_df %>% mutate_all(as.character), "wp_all_posts.csv", na="", quote="all", col_names = F)
#post meta
postmeta_files<-list.files("./",recursive = T, pattern = "wp_postmeta", full.names = T)
# check creating time
file.info(postmeta_files)$mtime
all_postmeta<-list()
for(i in 1:length(postmeta_files)){
all_postmeta[[i]]<-read_csv2(file = postmeta_files[i], col_names = F, col_types = cols(.default = "c"))
}
sapply(all_postmeta, ncol)
all_postmeta_df<-bind_rows(all_postmeta)
# export
write_csv2(all_postmeta_df %>% mutate_all(as.character), "wp_all_postmeta.csv", na="", quote="all", col_names = F)
### Make terms databasts
##################################
# set up working environment
##################################
setwd("~/Documents/upwork/tavad/migrate salus/terms/")
library(tidyverse)
library(lubridate)
library(readxl)
library(fuzzyjoin)
##################################
# load user and ingreso information
##################################
users<-read_csv("../user/out/all_user_info.csv")
ingresos<-read_csv("../user/out/ingresos.csv")
# round dates
ingresos<-ingresos %>%
mutate(fecha_ingreso=as.Date(format(fecha_ingreso, "%Y-%m-%d")),
fecha_fin=as.Date(format(fecha_fin,"%Y-%m-%d")))
# adjust the dates to also catch visits before and after that may be displaced by a few days
ingresos<-ingresos %>%
group_by(hce) %>%
mutate(
# specify start date 90 days before first visit, and then 30 days before any subsequent visits
fecha_start=case_when(
fecha_ingreso==min(fecha_ingreso)~fecha_ingreso-90,
TRUE~fecha_ingreso-30),
# end date is always 30 days before the next visit
fecha_end=fecha_fin-30)
##################################
# get post slugs
##################################
all_posts_df<-read_csv2(file = "../posts/wp_all_posts.csv", col_names = F, col_types = cols(.default = "c"))
# check no posts are duplicated
all_posts_df$X1 %>% duplicated() %>% any() # should be false
# extract slugs
post_id<-all_posts_df$X1
post_slugs<-all_posts_df$X6
post_dates<-format(as_datetime(all_posts_df$X3), "%Y-%m-%d")
#split post slugs
post_info=tibble(
post_object_id=post_id,
post_date=as_date(post_dates),
post_slug=post_slugs) %>%
separate(post_slug, into=c("us","user_id","tr","post_id","post_type"), sep = "-") %>%
select(-c(us, tr)) %>%
mutate(user_id=as.numeric(user_id)) %>%
## pull in hce
left_join(users %>%
select(user_id=ID, hce)) %>%
## arrange
arrange(user_id, post_date)
## check NA's
post_info %>%
filter(is.na(user_id)) # should be none, but these will just get lost in the system.. nothing we can do
## free up memory
rm(post_id, post_dates, post_slugs)
##################################
# group posts into terms
##################################
## 1. delimit posts into terms based on fecha de ingreso lists
### this seems to take up too much memory...to do in one go
##$ to overcome memory issues, split df into groups based on hce
post_info_list<-post_info %>%
group_by(hce) %>%
group_split(.keep = T)
# make new empty list
pst_list2<-list()
# run fuzzy join per hce
for(i in 1:length(post_info_list)) {
print(i)
# for ingresos filter, to speed up loop
nhc=post_info_list[[i]]$hce[1]
# fuzzy join
pst_list2[[i]]<-post_info_list[[i]] %>%
fuzzy_left_join(ingresos %>%
filter(hce==nhc),
by = c("hce" = "hce",
"post_date" = "fecha_start",
"post_date" = "fecha_end"),
match_fun = list(`==`, `>=`, `<`)) %>%
select(-c(tipo_tratamiento, hce.y)) %>%
rename(hce=hce.x)
}
#join again
post_info_merged <-pst_list2 %>%
bind_rows()
## 2. delimit all remaining posts based on a 6-month gap rule (no posts for 6 months means a new treatment has started)
post_info_nas<-post_info_merged %>%
filter(is.na(tratamiento)) %>%
## make term ids. These should be unique per user, but may be duplicated if a user has had a relapse
## Threshold for new session is set to >183 days between any visits
#filter(user_id %in% c("356","1419")) %>%
group_by(hce) %>%
arrange(hce, post_date) %>%
mutate(days_since_first_visit=as.numeric(post_date-min(post_date)),
days_since_last_visit = as.numeric(days_since_first_visit-lag(days_since_first_visit, default = 0))) %>%
mutate(tratamiento=ifelse(days_since_last_visit-180>1, 1, 0)) %>%
mutate(tratamiento=cumsum(tratamiento)) %>%
ungroup() %>%
group_by(hce, tratamiento) %>%
mutate(fecha_ingreso=as.Date(format(post_date[1],"%Y-%m-%d")),
estado="no-realizo-ingreso") %>%
select(-c(days_since_first_visit,days_since_last_visit)) %>%
ungroup()
## 3. combine the two tables
post_info_all<-post_info_merged %>%
select(-c(fecha_start, fecha_end, fecha_fin)) %>%
left_join(post_info_nas %>%
select(post_object_id, tratamiento,estado, fecha_ingreso),
by="post_object_id")  %>%
mutate(tratamiento=coalesce(tratamiento.x, tratamiento.y),
estado=coalesce(estado.x, estado.y),
fecha_ingreso=coalesce(fecha_ingreso.x, fecha_ingreso.y)) %>%
select(-c(fecha_ingreso.x, fecha_ingreso.y, tratamiento.x, tratamiento.y, estado.x, estado.y)) %>%
## make term ids
group_by(hce, fecha_ingreso) %>%
mutate(term_id=paste0(hce,as.character(format(as.Date(fecha_ingreso), "%Y%m%d")))) %>%
ungroup()
## 4. summarise info
## count numbers of treatments per user and export
post_info_all %>%
group_by(user_id) %>%
summarise("n_tratamientos"=length(unique(term_id))) %>%
arrange(desc(n_tratamientos)) %>%
left_join(users %>%
select(ID, hce),
by=c("user_id"="ID")) %>%
select(hce, user_id, n_tratamientos) %>%
print() %>%
write_csv("~/Downloads/numero_tratamientos_por_usuario.csv")
## export the full post/terms list
post_info_all %>%
write_csv("out/all_terms_list.csv", na="")
#post_info_all<-read_csv("./out/all_terms_list.csv")
##################################
# make wp_terms and wp_termmeta
##################################
## load empty wp templates
wp_terms_in<-read_csv2("../templates/wp_terms.csv")
wp_termmeta_in<-read_csv2("../templates/wp_termmeta.csv")
wp_terms <- post_info_all %>%
group_by(term_id) %>%
slice_head(n=1) %>%
mutate(name=paste("tr-us",user_id, "fe",term_id, sep="-"),
slug=name,
term_group=0) %>%
select(term_id, name,slug,term_group)
## prep term meta
wp_termmeta<-post_info_all %>%
group_by(term_id) %>%
slice_head(n=1) %>%
mutate(fecha=as.character(fecha_ingreso),
estado=estado,
paciente=as.character(user_id)) %>%
ungroup()%>%
select(term_id, fecha,estado,paciente) %>%
pivot_longer(-term_id, names_to="meta_key" , values_to = "meta_value") %>%
drop_na(meta_value) %>%
mutate(meta_id = row_number()+1000) %>% ### DANGER!!! adding ids manually
select(meta_id, term_id, meta_key, meta_value)
## export
write_csv2(wp_terms %>% mutate_all(as.character), "./out/wp_terms.csv", na="", quote="all", col_names = F)
write_csv2(wp_termmeta %>% mutate_all(as.character), "./out/wp_termmeta.csv", na="", quote="all", col_names = F)
##################################
# make wp_term_relationships
##################################
## load empty wp templates
wp_term_relationships_in<-read_csv2("../templates/wp_term_relationships.csv")
wp_term_relationships_in
# make new wp_term_relationships
wp_term_relationships <- tibble(
object_id=post_info_all$post_object_id,
term_taxonomy_id=post_info_all$term_id,
term_order=0
)
write_csv2(wp_term_relationships %>% mutate_all(as.character), "./out/wp_term_relationships.csv", na="", quote="all", col_names = F)
### make user meta
## this requires a clean users list and a terms id list. Run this after all posts have been run first, then the terms_id
##################################
# set up working environment
##################################
setwd("~/Documents/upwork/tavad/migrate salus/user/")
library(tidyverse)
library(lubridate)
library(readxl)
##################################
# import data
##################################
# user info
users<-read_csv("out/all_user_info.csv")
# term ids
terms<-read_csv("../terms/out/all_terms_list.csv")
# posts
posts<-read_csv2("../posts/wp_all_posts.csv",col_names = F)
##################################
# correct fecha ingreso and make status
##################################
## add fecha ingreso
users<-users %>%
left_join(terms %>%
select(user_id, fecha_ingreso)%>%
arrange(user_id,fecha_ingreso) %>%
group_by(user_id) %>%
summarise(fecha_ingreso=min(fecha_ingreso)),
by=c("ID"="user_id"))
# wp_usermeta template
wp_usermeta_in<-read_csv2("../templates/wp_usermeta.csv")
wp_usermeta_in$meta_key %>% unique()
# populate wp_usermeta
## summarize all treatments per users and store as array
terms_per_user<-terms %>%
select(user_id, term_id) %>%
distinct_all() %>%
group_by(user_id) %>%
summarise(tratamientos=paste0(
#top level
paste0('a:',n(),':{'),
# individual arrays
paste0('i:',(row_number()-1),';d:'
,term_id, collapse=";"),';}')
) %>%
ungroup() %>%
mutate(user_id=as.numeric(user_id)) %>%
drop_na()
terms_per_user
## summarize all specialists per users and store as string
specialists_per_user<-posts %>%
separate(X6, into = c("us","user_id","tr","term","post"), sep = "-") %>%
select(user_id, especialista=X2) %>%
group_by(user_id) %>%
summarise(especialista=paste(unique(especialista) %>% na.omit(),collapse=";"))
specialists_per_user
### add new meta keys and pivot template wider
wp_usermeta_wide<-wp_usermeta_in %>%
pivot_wider(id_cols=user_id, names_from = meta_key, values_from = meta_value) %>%
# correct data types to match
mutate(nacimiento=as.Date(nacimiento)) %>%
## remove all entries
slice_head(n=0) %>%
## append entries based on the users document
bind_rows(users %>%
rename(user_id=ID) %>%
mutate(wp_user_level=as.character(wp_user_level)) %>%
select(user_id, intersect(colnames(users), wp_usermeta_in$meta_key))) %>%
## add term list per user.
left_join(terms_per_user, by="user_id")  %>%
## add speciaslits
mutate(user_id=as.character(user_id)) %>%
left_join(specialists_per_user, by="user_id")
## pivot longer again and incorporate into wp_usermeta
wp_usermeta<-wp_usermeta_wide %>%
# change formats to text
mutate_all(as.character) %>%
pivot_longer(-user_id, names_to = "meta_key", values_to = "meta_value") %>%
# make meta id
mutate(umeta_id=1:n() + 5000) %>% # !!!DANGER.- appending id's manually
select(umeta_id, everything()) %>%
# drop empty rows
mutate(meta_value=na_if(meta_value,"")) %>%
drop_na(meta_value)
write_csv2(wp_usermeta %>% mutate_all(as.character),"./out/wp_usermeta.csv", na="", quote="all", col_names = F)
View(wp_usermeta)
### make posts subset for specific users
##################################
# set up working environment
##################################
setwd("~/Documents/upwork/tavad/migrate salus/user/")
library(tidyverse)
library(lubridate)
library(readxl)
##################################
# import data
##################################
# user info
users<-read_csv("out/all_user_info.csv")
# posts
posts<-read_csv2("../posts/wp_all_posts.csv",col_names = F)
postmeta<-read_csv2("../posts/wp_all_postmeta.csv", col_names = F)
##################################
# subset data
##################################
## filter by name
#test_users<-users %>%
#  filter(nombre %in% c("Rodriguez Sanchez, Victor","Legarra Sabada, Jaime","Alvarez Piñal, Carlos","Peris Gallego, Antonio")) %>%
#  pull(ID)
## filter by hce
test_users<-users %>%
filter(hce %in% c("006655","002471","005132","007548","006863")) %>%
pull(ID)
test_posts<-posts %>%
separate(X6, into = c("us","user_id","tr","term","post"), sep = "-", remove = F) %>%
filter(user_id %in% test_users) %>%
select(-c("us","user_id","tr","term","post"))
test_postmeta<-postmeta %>%
filter(X2 %in% test_posts$X1)
##################################
# export
##################################
write_csv2(test_posts %>%
select(starts_with("X"))%>%
mutate_all(as.character),
"../posts/wp_test_posts.csv", na="", quote="all", col_names = F)
write_csv2(test_postmeta %>% mutate_all(as.character), "../posts/wp_test_postmeta.csv", na="", quote="all", col_names = F)
View(test_postmeta)
test_postmeta %>% filter(X3=="metaPaciente", X4=="17")
View(test_postmeta)
# set working directory
setwd("~/Documents/git_projects/ADDA_taller2/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse,DESeq2,viridis,scales)
txi<-readRDS("./data/salmon_gene_counts.rds")
samples<-read_csv("./data/design_matrix.csv")
samples <- samples %>%
filter(tissue=="skin") %>%
mutate(condition=as.factor(paste(treatment, side, sep="_")))
samples
samples$sample_id
txi$abundance
## filter txi matrices
txi$abundance<-txi$abundance[,samples$sample_id]
txi$counts<-txi$counts[,samples$sample_id]
txi$length<-txi$length[,samples$sample_id]
dds <- DESeqDataSetFromTximport(txi,
colData = samples,
design = ~ condition)
colData(dds)
rowData(dds)
metadata(dds)
assays(dds)
assayNames(dds)
