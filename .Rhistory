"the output below update to reflect the value you",
"entered at the top:")
library(shiny)
library(tidyverse)
ui <- fluidPage(
textInput(inputId = "caption",
label="Caption",
value=3),
submitButton("Update View", icon("refresh")),
helpText("When you click the button above, you should see",
"the output below update to reflect the value you",
"entered at the top:"),
verbatimTextOutput("value"),
plotOutput("barplot")
)
server <- function(input, output) {
dat <- reactive({
data.frame(x=letters[1:input$caption], y=rnorm(n=input$caption))
})
output$barplot <- renderPlot({
dat() %>%
ggplot(aes(x=x, y=y)) +
geom_bar(stat="identity")
})
}
shinyApp(ui, server)
library(tidyverse)
library(rvest)
doc <- read_html("https://bioweb.bio/faunaweb/amphibiaweb/EspeciesEstadisticas/EndemicasOrden/Anura")
html_nodes(doc, xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[3]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
html_nodes(doc, "[class='ng-binding']") %>%
html_text()
doc %>%
html_nodes("[class='ng-binding']") %>%
html_text()
doc %>%
html_nodes("h2") %>%
html_text()
doc
doc %>%
html_nodes(css=".toctext") %>%
html_text()
doc %>%
html_nodes(xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[1]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
doc <- read_html("https://bioweb.bio/faunaweb/amphibiaweb/EspeciesEstadisticas/EndemicasOrden/Anura")
doc %>%
html_nodes(xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[1]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
doc %>%
html_element("h2")
starwars <- read_html("https://rvest.tidyverse.org/articles/starwars.html")
doc %>%
html_element("h2") %>%
html_text()
doc %>%
html_nodes("div.col-xs-12") %>%
html_text()
doc %>%
html_nodes("a.ng-scope") %>%
html_text()
library(AmphiNom)
aswSearch(query = "Bufo bufo")
aswSearch
install.packages("RSelenium")
library(RSelenium)
library(httr)
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"
# Query webpage
bbc <- GET("https://www.bbc.com/",
user_agent(ua))
# Confirm it's actually used the desired user agent
bbc$request$options$useragent
# Query webpage
bbc <- GET("https://amphibiansoftheworld.amnh.org/",
user_agent(ua))
# Confirm it's actually used the desired user agent
bbc$request$options$useragent
aswSearch
# Query webpage
bb <- GET("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent(ua))
# Confirm it's actually used the desired user agent
bb$request$options$useragent
bb
parse_rvest <- read_html("http://testing-ground.scraping.pro/",
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0")
library(rvest)
parse_rvest <- read_html("http://testing-ground.scraping.pro/",
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0")
parse_rvest <- read_html("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent = ua)
parse_rvest <- read_html("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",user_agent = ua)
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
x <- GET(url, add_headers('user-agent' = 'Gov employment data scraper ([[your email]])'))
x %>%
read_html()
ua
x <- GET(url, add_headers('user-agent' = ua))
x %>%
read_html()
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
# Query webpage
bb <- GET("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent(ua))
bb
bb %>%
read_html()
#####
ua="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
x <- GET(url, add_headers('user-agent' = ua))
x %>%
read_html()
x <- GET(url, add_headers('user-agent' = ua),user_agent(ua))
x %>%
read_html()
library(RSelenium)
library(rvest)
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
remDr <- rD[["client"]]
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
remDr <- rD[["client"]]
remDr$navigate(fund_link)
remDr$switchToFrame(NULL)
fund_page = xml2::read_html(remDr$getPageSource()[[1]])
fund_page %>% read_html()
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
rD <- rsDriver(browser="firefox", port=4545L, verbose=F)
rD <- rsDriver(browser="firefox", port=4545L, verbose=T)
suppressWarnings(tryCatch(rm(remDr),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){}))
gc()
suppressWarnings(tryCatch(rm(remDr),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){})
rD <- rsDriver(browser="firefox", port=4545L, verbose=T)
rD1 <- rsDriver(browser = "chrome", port = 4567L, geckover = NULL,
chromever =  "latest", iedrver = NULL,
phantomver = NULL, extraCapabilities = cprof)
rD1 <- rsDriver(browser = "chrome", port = 4567L, geckover = NULL,
chromever =  "latest", iedrver = NULL,
phantomver = NULL)
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua))
url="https://stackoverflow.com/questions/64391812/scrape-site-that-asks-for-cookies-consent-with-rvest"
# Query webpage
bb <- GET(url,
user_agent(ua))
bb
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua))
bb
# Confirm it's actually used the desired user agent
bb$request$options$useragent
bb$request$options
bb$request
header="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers("header"=header))
bb$request
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers("Headers"=header))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
header=c("text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
"application/font-woff2;q=1.0,application/font-woff;q=0.9,*/*;q=0.8")
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
# Query webpage
bb <- GET(url,
#user_agent(ua),
#add_headers(Accept=header),
#accept = "application/zip",
user_agent("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
#user_agent(ua),
#add_headers(Accept=header),
accept = "application/zip",
user_agent("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"))
# Confirm it's actually used the desired user agent
bb$request
bb
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header),
httpget=F
)
# Confirm it's actually used the desired user agent
bb$request
header=c("text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8")
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header),
)
# Confirm it's actually used the desired user agent
bb$request
library(devtools)
install_github("hcliedtke/AmphiNom", build_vignettes = TRUE)
install_github("hcliedtke/AmphiNom", build_vignettes = FALSE)
setwd("~/Documents/upwork/richard_wheeler/ai_dashboards")
#### cf
devtools::install_github("hrbrmstr/cfhttr")
library(cfhttr)
res <- cf_GET(url)
install.packages(c("ade4", "ape", "aplot", "arules", "backports", "bayesplot", "betapart", "BH", "BiocManager", "blob", "blogdown", "bookdown", "boot", "brew", "brio", "brms", "Brobdingnag", "broom", "bslib", "cachem", "car", "carData", "caret", "checkmate", "class", "clipr", "cluster", "colorspace", "commonmark", "compositions", "conquer", "corHMM", "corpcor", "corrplot", "cpp11", "credentials", "crosstalk", "cubature", "dashboardthemes", "data.table", "DBI", "DEoptimR", "desc", "deSolve", "devtools", "diffobj", "distributional", "diversitree", "doMC", "doParallel", "doSNOW", "downlit", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "extrafont", "fable", "fabletools", "fastmatch", "fdrtool", "feasts", "fontawesome", "foreach", "forecast", "foreign", "formatR", "fs", "future", "future.apply", "gargle", "generics", "geometry", "gert", "GGally", "ggdist", "ggfun", "ggnewscale", "ggspectra", "gh", "gmp", "googledrive", "googlesheets4", "gprofiler2", "graphlayouts", "gtools", "haven", "highcharter", "hisse", "Hmisc", "hms", "htmlTable", "htmlwidgets", "httpuv", "hyperSpec", "igraph", "iterators", "jpeg", "kernlab", "KernSmooth", "klaR", "knitr", "lars", "later", "lattice", "lavaan", "leaflet", "lightr", "linprog", "lme4", "lmtest", "loo", "lubridate", "magic", "magick", "magrittr", "maps", "maptools", "MASS", "mathjaxr", "Matrix", "matrixStats", "mclust", "memoise", "mgcv", "misc3d", "MuMIn", "mvtnorm", "nlme", "nloptr", "nnet", "odbc", "openxlsx", "packrat", "pander", "parallelly", "pavo", "pbapply", "permute", "photobiology", "photobiologyWavebands", "phytools", "pkgbuild", "pkgdown", "pkgload", "plotly", "plotrix", "pls", "plyr", "polynom", "posterior", "processx", "progressr", "prospectr", "proxy", "psych", "qgraph", "quantreg", "R.utils", "ragg", "raster", "rattle", "rcdd", "rcmdcheck", "RColorBrewer", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "readr", "readxl", "recipes", "remotes", "reprex", "resemble", "reshape", "reticulate", "rex", "rgdal", "rgeos", "rio", "rjson", "rlist", "rmarkdown", "Rmpfr", "rncl", "RNeXML", "robustbase", "RODBC", "roxygen2", "rpart", "rprojroot", "rsconnect", "RSQLite", "rstan", "rstantools", "Rttf2pt1", "runner", "rvcheck", "rversions", "s2", "sass", "scales", "scholar", "segmented", "servr", "sessioninfo", "sf", "sfsmisc", "shiny", "shinydashboard", "shinyjs", "shinystan", "shinyWidgets", "simsalapar", "slam", "slider", "snow", "sp", "spam", "spatial", "styler", "subplex", "survival", "svglite", "systemfonts", "terra", "testthat", "textshaping", "tidybayes", "tidygraph", "tidyr", "tidyselect", "tidytree", "tinytex", "toOrdinal", "tsbox", "tseries", "tsibble", "tsibbledata", "TTR", "units", "usethis", "uuid", "vctrs", "vegan", "viridis", "visNetwork", "vroom", "waldo", "webshot", "withr", "wk", "xfun", "XML", "yaml", "zip", "zoo"))
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse, pheatmap)
txi<-readRDS("./data/salmon_gene_counts.rds")
# set working directory
setwd("~/Documents/git_projects/ADDA_taller2_2022/")
txi<-readRDS("./data/salmon_gene_counts.rds")
class(txi)
apply(txi, head)
lapply(txi, head)
apply(X=txi$abundance, FUN=sum, MARGIN = 2)
hist(log10(txi$abundance[,1]), breaks=50)
txi$abundance %>%
as_tibble(rownames = "transcript") %>%
pivot_longer(-transcript, names_to="sample", values_to="TPM") %>%
ggplot(aes(x=TPM)) +
geom_histogram() +
ylab("number of transcripts") +
scale_x_log10() +
facet_wrap(~sample)
str(txi)
txi %>% str()
txi$abundance
txi$abundance
txi$abundance %>%
head()
txi$abundance %>%
as.data.frame(rownames = "transcript") %>%
head()
txi$abundance %>%
as_tibble(rownames = "transcript") %>%
head()
txi_tidy<-txi$abundance %>%
as_tibble(rownames = "transcript") %>%
pivot_longer(-transcript, names_to="sample", values_to="TPM")
txi_tidy
###
abundance<-txi$abundance %>% head(n=50)
head(abundance)
View(abundance)
plot(x=abundance[,1], y=abundance[,2])
abundance_wide <- abundance %>%
pivot_longer(names_to = "samples", values_to = "abundance")
abundance_wide <- abundance %>%
as.data.frame() %>%
pivot_longer(names_to = "samples", values_to = "abundance")
abundance_wide <- abundance %>%
as_tibble(rownames = "transcripts") %>%
pivot_longer(-1, names_to = "samples", values_to = "abundance")
abundance_wide
View(abundance_wide)
View(abundance)
abundance_long <- abundance %>%
as_tibble(rownames = "transcripts") %>%
pivot_longer(-1, names_to = "samples", values_to = "abundance")
abundance_long
abundance_long %>%
ggplot(aes(x=TPM)) +
geom_histogram()
abundance_long %>%
ggplot(aes(x=abundance)) +
geom_histogram()
abundance_long %>%
ggplot(aes(x=abundance)) +
geom_histogram() +
facet_wrap(~sample)
abundance_long %>%
ggplot(aes(x=abundance)) +
geom_histogram() +
facet_wrap(~samples)
samples<-read.csv("./data/design_matrix.csv")
View(samples)
table(samples[,c("treatment","tissue")])
# remove 0-variance genes
tpm<-txi$abundance %>%
as.data.frame() %>%
filter_all(any_vars(. != 0))
# perfomr PCA on TRANSPOSED scaled, centred TPMs
pca<- prcomp(t(tpm),scale.=T, center=T)
t
?t
tpm %>% head()
tpm %>% head() %>% t()
pca
pca$x
plot(pca$x[,1:2])
View(samples)
## add metadata and plot
pca$x %>%
as_tibble(rownames = "sample_id") %>%
left_join(samples)
## add metadata and plot
pca$x %>%
as_tibble(rownames = "sample_id") %>%
left_join(samples) -> test
View(test)
colname(samples)
colnames(samples)
colnames(samples)[1]
colnames(samples)[1]<-"sample_id"
colnames(samples)
pca$x %>%
as_tibble(rownames = "sample_id") %>%
left_join(samples)
## add metadata and plot
pca$x %>%
as_tibble(rownames = "sample_id") %>%
left_join(samples) %>%
ggplot(aes(x=PC1, y=PC2, color=treatment, shape=tissue)) +
geom_point(size=3)
# get sample-to-sample distance
sample_dist <- dist(t(tpm))
sample_dist
# convert to matrix
sample_dist_matrix <- as.matrix(sample_dist)
# plot
pheatmap(sample_dist_matrix,
scale = "row",
annotation_col=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"),
annotation_row=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"))
# plot
pheatmap(TPM,
scale = "row",
annotation_col=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"),
annotation_row=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"))
# plot
pheatmap(tpm,
scale = "row",
annotation_col=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"),
annotation_row=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"))
# use pacman to load libraries
pacman::p_load(tidyverse, pheatmap)
txi<-readRDS("./data/salmon_gene_counts.rds")
samples<-read.csv("./data/design_matrix.csv")
tpm<-txi$abundance %>%
as.data.frame() %>%
filter_all(any_vars(. != 0))
pheatmap(sample_dist_matrix,
scale = "row",
annotation_col=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"),
annotation_row=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"))
pheatmap(tpm,
scale = "row",
annotation_col=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"),
annotation_row=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"))
pheatmap(t(tpm),
scale = "row",
annotation_col=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"),
annotation_row=data.frame(samples[,c("sample_id","tissue","treatment","side")], row.names = "sample_id"))
# set working directory
setwd("~/Documents/git_projects/ADDA_taller2_2022/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse, DESeq2,viridis,scales)
txi<-readRDS("./data/salmon_gene_counts.rds")
samples<-read_csv("./data/design_matrix.csv")
View(samples)
samples <- samples %>%
filter(tissue=="skin") %>%
mutate(condition=as.factor(paste(treatment, side, sep="_")))
samples$sample_id
samples$sample_id
## filter txi matrices
txi$abundance<-txi$abundance[,samples$sample_id]
txi$counts<-txi$counts[,samples$sample_id]
txi$length<-txi$length[,samples$sample_id]
colnames(txi$abundance)
dds <- DESeqDataSetFromTximport(txi,
colData = samples,
design = ~ condition)
dds
assays(dds)
counts(dd)
counts(dds)
counts(dds) %>% head()
colData(dds)
rowData(dds)
dds <- dds[rowSums(counts(dds)) >= 10,]
vst_counts <- vst(dds, blind=F)
plotPCA(vst_counts,
intgroup=c("side", "treatment"), # indicate how to label the points
returnData=F, # plot only
ntop=500) # use only 500 most variable genes.
dds <- DESeq(dds)
dds
dds
resultsNames(dds)
unique(samples$condition)
# 1. using the result names:
results(dds, name="condition_white_dorsal_vs_black_dorsal")
# 2. using contrasts:
results(dds, contrast=c("condition","white_dorsal","black_dorsal"))
# white dorsal vs white ventral
res_wD_wV<-results(dds, contrast=c("condition","white_dorsal","white_ventral"))
# black dorsal vs black ventral
res_bD_bV<-results(dds, contrast=c("condition","black_dorsal","black_ventral"))
# black dorsal vs white dorsal
res_bD_wD<-results(dds, contrast=c("condition","black_dorsal","white_dorsal"))
# black ventral vs white ventral
res_bV_wV<-results(dds, contrast=c("condition","black_ventral","white_ventral"))
res_bV_wV
res_bV_wV
res<-list(bD_bV = res_bD_bV,
wD_wV = res_wD_wV,
bV_wV = res_bV_wV,
bD_wD = res_bD_wD)
summary(res_bD_bV)
lapply(X=res,summary)
###
# single plot:
res_bD_bV %>% head()
hist(res_bD_bV$pvalue, breaks=50, col="grey", main="")
res_bD_bV
summary(res_bD_bV)
# for all comparisons:
par(mfrow=c(2,2))
par(mar=c(4,4,1,1))
for(i in names(res)){
hist(res[[i]]$pvalue, breaks=50, col="grey", main=i, xlab = "p-value")
}
plotDispEsts(dds)
plotDispEsts(dds)
res_bD_bV
DESeq2::plotMA(res_bD_bV)
# all comparisons (with lapply)
par(mfrow=c(2,2)) # divide plot area in 4
lapply(names(res),function(i) DESeq2::plotMA(res[[i]], main=i, alpha=0.05))
res_bD_bV %>%
as.data.frame() %>%
ggplot(aes(baseMean, log2FoldChange, colour=padj)) +
geom_point(size=1) +
scale_y_continuous(limits=c(-3, 3), oob=squish) + # oob from the scales package is needed to "squish" points falling outside the axis limits
scale_x_log10() +
geom_hline(yintercept = 0, colour="red", size=1, linetype="longdash") +
labs(x="mean of normalized counts", y="log fold change") +
scale_colour_viridis(direction=-1, trans='sqrt') +
geom_density_2d(colour="blue", size=0.5) +
theme_bw()
res_bD_bV %>% nrow()
