})
output$barplot <- renderPlot({
dat() %>%
ggplot(aes(x=x, y=y)) +
geom_bar(stat="identity")
})
}
shinyApp(ui, server)
submitButton("Update View", icon("refresh")),
helpText("When you click the button above, you should see",
"the output below update to reflect the value you",
"entered at the top:")
library(shiny)
library(tidyverse)
ui <- fluidPage(
textInput(inputId = "caption",
label="Caption",
value=3),
submitButton("Update View", icon("refresh")),
helpText("When you click the button above, you should see",
"the output below update to reflect the value you",
"entered at the top:"),
verbatimTextOutput("value"),
plotOutput("barplot")
)
server <- function(input, output) {
dat <- reactive({
data.frame(x=letters[1:input$caption], y=rnorm(n=input$caption))
})
output$barplot <- renderPlot({
dat() %>%
ggplot(aes(x=x, y=y)) +
geom_bar(stat="identity")
})
}
shinyApp(ui, server)
library(tidyverse)
library(rvest)
doc <- read_html("https://bioweb.bio/faunaweb/amphibiaweb/EspeciesEstadisticas/EndemicasOrden/Anura")
html_nodes(doc, xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[3]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
html_nodes(doc, "[class='ng-binding']") %>%
html_text()
doc %>%
html_nodes("[class='ng-binding']") %>%
html_text()
doc %>%
html_nodes("h2") %>%
html_text()
doc
doc %>%
html_nodes(css=".toctext") %>%
html_text()
doc %>%
html_nodes(xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[1]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
doc <- read_html("https://bioweb.bio/faunaweb/amphibiaweb/EspeciesEstadisticas/EndemicasOrden/Anura")
doc %>%
html_nodes(xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[1]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
doc %>%
html_element("h2")
starwars <- read_html("https://rvest.tidyverse.org/articles/starwars.html")
doc %>%
html_element("h2") %>%
html_text()
doc %>%
html_nodes("div.col-xs-12") %>%
html_text()
doc %>%
html_nodes("a.ng-scope") %>%
html_text()
library(AmphiNom)
aswSearch(query = "Bufo bufo")
aswSearch
install.packages("RSelenium")
library(RSelenium)
library(httr)
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"
# Query webpage
bbc <- GET("https://www.bbc.com/",
user_agent(ua))
# Confirm it's actually used the desired user agent
bbc$request$options$useragent
# Query webpage
bbc <- GET("https://amphibiansoftheworld.amnh.org/",
user_agent(ua))
# Confirm it's actually used the desired user agent
bbc$request$options$useragent
aswSearch
# Query webpage
bb <- GET("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent(ua))
# Confirm it's actually used the desired user agent
bb$request$options$useragent
bb
parse_rvest <- read_html("http://testing-ground.scraping.pro/",
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0")
library(rvest)
parse_rvest <- read_html("http://testing-ground.scraping.pro/",
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0")
parse_rvest <- read_html("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent = ua)
parse_rvest <- read_html("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",user_agent = ua)
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
x <- GET(url, add_headers('user-agent' = 'Gov employment data scraper ([[your email]])'))
x %>%
read_html()
ua
x <- GET(url, add_headers('user-agent' = ua))
x %>%
read_html()
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
# Query webpage
bb <- GET("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent(ua))
bb
bb %>%
read_html()
#####
ua="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
x <- GET(url, add_headers('user-agent' = ua))
x %>%
read_html()
x <- GET(url, add_headers('user-agent' = ua),user_agent(ua))
x %>%
read_html()
library(RSelenium)
library(rvest)
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
remDr <- rD[["client"]]
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
remDr <- rD[["client"]]
remDr$navigate(fund_link)
remDr$switchToFrame(NULL)
fund_page = xml2::read_html(remDr$getPageSource()[[1]])
fund_page %>% read_html()
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
rD <- rsDriver(browser="firefox", port=4545L, verbose=F)
rD <- rsDriver(browser="firefox", port=4545L, verbose=T)
suppressWarnings(tryCatch(rm(remDr),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){}))
gc()
suppressWarnings(tryCatch(rm(remDr),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){})
rD <- rsDriver(browser="firefox", port=4545L, verbose=T)
rD1 <- rsDriver(browser = "chrome", port = 4567L, geckover = NULL,
chromever =  "latest", iedrver = NULL,
phantomver = NULL, extraCapabilities = cprof)
rD1 <- rsDriver(browser = "chrome", port = 4567L, geckover = NULL,
chromever =  "latest", iedrver = NULL,
phantomver = NULL)
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua))
url="https://stackoverflow.com/questions/64391812/scrape-site-that-asks-for-cookies-consent-with-rvest"
# Query webpage
bb <- GET(url,
user_agent(ua))
bb
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua))
bb
# Confirm it's actually used the desired user agent
bb$request$options$useragent
bb$request$options
bb$request
header="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers("header"=header))
bb$request
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers("Headers"=header))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
header=c("text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
"application/font-woff2;q=1.0,application/font-woff;q=0.9,*/*;q=0.8")
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
# Query webpage
bb <- GET(url,
#user_agent(ua),
#add_headers(Accept=header),
#accept = "application/zip",
user_agent("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
#user_agent(ua),
#add_headers(Accept=header),
accept = "application/zip",
user_agent("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"))
# Confirm it's actually used the desired user agent
bb$request
bb
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header),
httpget=F
)
# Confirm it's actually used the desired user agent
bb$request
header=c("text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8")
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header),
)
# Confirm it's actually used the desired user agent
bb$request
library(devtools)
install_github("hcliedtke/AmphiNom", build_vignettes = TRUE)
install_github("hcliedtke/AmphiNom", build_vignettes = FALSE)
setwd("~/Documents/upwork/richard_wheeler/ai_dashboards")
#### cf
devtools::install_github("hrbrmstr/cfhttr")
library(cfhttr)
res <- cf_GET(url)
install.packages(c("ade4", "ape", "aplot", "arules", "backports", "bayesplot", "betapart", "BH", "BiocManager", "blob", "blogdown", "bookdown", "boot", "brew", "brio", "brms", "Brobdingnag", "broom", "bslib", "cachem", "car", "carData", "caret", "checkmate", "class", "clipr", "cluster", "colorspace", "commonmark", "compositions", "conquer", "corHMM", "corpcor", "corrplot", "cpp11", "credentials", "crosstalk", "cubature", "dashboardthemes", "data.table", "DBI", "DEoptimR", "desc", "deSolve", "devtools", "diffobj", "distributional", "diversitree", "doMC", "doParallel", "doSNOW", "downlit", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "extrafont", "fable", "fabletools", "fastmatch", "fdrtool", "feasts", "fontawesome", "foreach", "forecast", "foreign", "formatR", "fs", "future", "future.apply", "gargle", "generics", "geometry", "gert", "GGally", "ggdist", "ggfun", "ggnewscale", "ggspectra", "gh", "gmp", "googledrive", "googlesheets4", "gprofiler2", "graphlayouts", "gtools", "haven", "highcharter", "hisse", "Hmisc", "hms", "htmlTable", "htmlwidgets", "httpuv", "hyperSpec", "igraph", "iterators", "jpeg", "kernlab", "KernSmooth", "klaR", "knitr", "lars", "later", "lattice", "lavaan", "leaflet", "lightr", "linprog", "lme4", "lmtest", "loo", "lubridate", "magic", "magick", "magrittr", "maps", "maptools", "MASS", "mathjaxr", "Matrix", "matrixStats", "mclust", "memoise", "mgcv", "misc3d", "MuMIn", "mvtnorm", "nlme", "nloptr", "nnet", "odbc", "openxlsx", "packrat", "pander", "parallelly", "pavo", "pbapply", "permute", "photobiology", "photobiologyWavebands", "phytools", "pkgbuild", "pkgdown", "pkgload", "plotly", "plotrix", "pls", "plyr", "polynom", "posterior", "processx", "progressr", "prospectr", "proxy", "psych", "qgraph", "quantreg", "R.utils", "ragg", "raster", "rattle", "rcdd", "rcmdcheck", "RColorBrewer", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "readr", "readxl", "recipes", "remotes", "reprex", "resemble", "reshape", "reticulate", "rex", "rgdal", "rgeos", "rio", "rjson", "rlist", "rmarkdown", "Rmpfr", "rncl", "RNeXML", "robustbase", "RODBC", "roxygen2", "rpart", "rprojroot", "rsconnect", "RSQLite", "rstan", "rstantools", "Rttf2pt1", "runner", "rvcheck", "rversions", "s2", "sass", "scales", "scholar", "segmented", "servr", "sessioninfo", "sf", "sfsmisc", "shiny", "shinydashboard", "shinyjs", "shinystan", "shinyWidgets", "simsalapar", "slam", "slider", "snow", "sp", "spam", "spatial", "styler", "subplex", "survival", "svglite", "systemfonts", "terra", "testthat", "textshaping", "tidybayes", "tidygraph", "tidyr", "tidyselect", "tidytree", "tinytex", "toOrdinal", "tsbox", "tseries", "tsibble", "tsibbledata", "TTR", "units", "usethis", "uuid", "vctrs", "vegan", "viridis", "visNetwork", "vroom", "waldo", "webshot", "withr", "wk", "xfun", "XML", "yaml", "zip", "zoo"))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,
eval = FALSE,
message=FALSE,
error=FALSE)
knitr::opts_knit$set(root.dir = '../')
library("webexercises")
# Chunk 2
# set working directory
setwd("~/Documents/git_projects/ADDA_taller2_2022/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse,DESeq2, ageglm,ggVennDiagram, UpSetR,plotly,ggrepel)
# Chunk 3
# DEG object
dds<-readRDS("./results/deseq2_dds.rds")
# the list of DEG results
res<-readRDS("./results/deseq2_results.rds")
# Load BLAST results
xtrop<-read_csv("./data/PCU23_annotations_xtr105.csv")
# Chunk 4
head(xtrop, 20)
# Chunk 5
xtrop<-read_csv("data/PCU23_annotations_xtr105_genes.csv")
# Chunk 6
summary(res$bD_bV, alpha=0.05)
# Chunk 7
# For a single comparison
res$bD_bV %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
# Chunk 8
# turn it into a function so we can apply it to a list!
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
}
# Chunk 9
#  extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
# Chunk 10
# comparing just the dorsal vs. ventral
ggVennDiagram(sig_deg[c("bD_bV","wD_wV")],
label_alpha = 0) +
scale_fill_gradient(low="blue",high = "gold")
# Chunk 11
ggVennDiagram(sig_deg,
label_alpha = 0) +
scale_fill_gradient(low="blue",high = "gold")
# Chunk 12
upset(fromList(sig_deg),
number.angles = 0, point.size = 3, line.size = 1,
sets.x.label = "Number of DEGs",
set_size.show	= TRUE,
set_size.scale_max = max(sapply(sig_deg, length))+50, # needed only to expand the axis a bit
text.scale = c(1.2, 1.2, 1.2, 1.2, 1.5, 1.5),
order.by=c("degree","freq"))
# Chunk 13
DESeq2::plotMA(res$bD_bV)
# Chunk 14
# apeglm shrinkage can only be done on already calculated coefficients:
resultsNames(dds)
bD_bV_res <- results(dds,
contrast= c("condition","white_ventral", "black_dorsal"))
bD_bV_res
# with shrinkage
bD_bV_shr<-lfcShrink(dds,
coef="condition_white_ventral_vs_black_dorsal",
type="apeglm")
bD_bV_shr
# Chunk 15
par(mfrow=c(1,2))
par(mar=c(4,4,4,1))
DESeq2::plotMA(bD_bV_res, main="MLE")
DESeq2::plotMA(bD_bV_shr, main="MAP")
# Chunk 16
par(mfrow=c(1,2))
par(mar=c(4,4,1,1))
# p values
plot(bD_bV_res$padj~bD_bV_shr$padj,
xlab="adjusted p-value (shrunk)",
ylab="adjusted p-value (MLE)")
# fold changes
plot(bD_bV_res$log2FoldChange~bD_bV_shr$log2FoldChange,
xlab="Fold Change (shrunk)",
ylab="Fold Change (MLE)")
par(mfrow=c(1,1))
# Chunk 17
res$bD_bV %>%
as_tibble(rownames = "gene_id") %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj))) +
geom_point(alpha=0.75, shape=16)
# Chunk 18
gg_res <- res %>%
lapply(as_tibble,rownames = "gene_id") %>%
bind_rows(.id="comparison") %>%
drop_na(padj) %>% # drop all genes with NAs
filter(padj<0.5) %>% # reduce the number of points that need to be plotted
mutate(sig= padj<0.05 & abs(log2FoldChange)>=2) %>% # make a variable to indicate if a gene is significant based on a specific thresholds
left_join(xtrop, by=c("gene_id")) %>% # add annotations
ggplot(aes(x=log2FoldChange, y=-log10(padj), color=sig,
text=paste0("</br>Pcu23 gene: ", gene_id,
"</br>Pcu23 peptide: ", pep_description,
"</br>X.tr peptide: ", xtr_pep_name_x
)
)) +
geom_point(alpha=0.75, shape=16) +
facet_wrap(~comparison, ncol = 2, scales = "free") +
xlim(-15,15) +
theme_minimal() +
theme(legend.position = "none")
ggplotly(gg_res, tooltip="text")
# Chunk 19
res$bD_wD %>%
as_tibble(rownames = "gene_id") %>%
drop_na(padj) %>% # drop all genes with NAs
#filter(padj<0.99) %>% # reduce the number of points that need to be plotted
mutate(sig= padj<0.05 & abs(log2FoldChange)>=2) %>% # make a variable to indicate if a gene is significant based on a specific thresholds
left_join(xtrop, by=c("gene_id")) %>% # add annotations
filter(padj<0.5) %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj), color=sig)) +
geom_point(alpha=0.75, shape=16) +
geom_text_repel(data=. %>% filter(sig),
aes(label=xtr_pep_name_x),
max.overlaps = 50,
size=2) +
xlim(-10,10) +
ggtitle("DEGs in Black Dorsal Skin in Comparison to White Dorsal Skin") +
theme_bw() +
theme(legend.position = "none")
View(res)
res[["bD_bV"]]
View(xtrop)
knitr::opts_chunk$set(echo = TRUE,
eval = FALSE,
message=FALSE,
error=FALSE)
knitr::opts_knit$set(root.dir = '../')
library("webexercises")
# set working directory
setwd("~/Documents/git_projects/ADDA_taller2_2022/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse,gprofiler2)
# the list of DEG results from the previous exercises
res<-readRDS("./results/deseq2_results.rds")
# the annotations
xtrop<-read_csv("./data/PCU23_annotations_xtr105.csv")
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
}
# now extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.1) %>%
pull(gene)
)
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.1) %>%
pull(gene)
)
}
# now extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
# make a function that extracts matching X. tropicalis IDs
extract_xtr<-function(x) {
return(
xtrop %>%
filter(gene_id %in% x) %>%
pull(xtr_pep_id_x) %>%
unique()
)
}
# apply function to list of Pelobates IDs
xtr_deg<-lapply(sig_deg, FUN=extract_xtr)
str(xtr_deg)
sapply(sig_deg, length)
sapply(xtr_deg, length)
xtr_bg<-extract_xtr(rownames(res$bD_bV))
str(xtr_bg)
# set base url:
set_base_url("http://biit.cs.ut.ee/gprofiler")
# run the analysis
res_ora<-gost(multi_query = FALSE, # returns separate results tables for multiquery
custom_bg = xtr_bg, # our background
query=xtr_deg, # our list of gene sets
organism="xtropicalis", # the organism our annotations belong to
exclude_iea = FALSE, # include GO terms that were electronically assigned
correction_method = "gSCS", # the recommended multiple testing correction.
sources=c("GO:BP","GO:CC","GO:MF", "KEGG","REAC"), # the functional sets we are interested in
evcodes=FALSE, ## evcodes TRUE needed for downstream analysis like enrichment maps in Cytoscape, but this takes longer.
significant= FALSE) # return all terms, not just the significant ones
# the results are stored as a "results" dataframe
head(res_ora$result)
res_ora$result %>%
filter(p_value<0.05) %>%
group_by(query) %>%
dplyr::count(query, sort=TRUE)
gostplot(res_ora)
res_ora$result %>%
select(query,term_name, p_value, intersection_size, query_size,source) %>%
filter(p_value<0.05) %>%
mutate(GeneRatio=intersection_size/query_size) %>%
arrange(GeneRatio) %>%
mutate(term_name = factor(term_name, levels=unique(term_name))) %>%
ggplot(aes(x=GeneRatio, y=term_name)) +
geom_point(aes(color=p_value, size=intersection_size)) +
ylab("") +
scale_colour_viridis_c(direction = 1, option = "magma") +
facet_grid(source~query,scales = "free_y",space = "free") +
theme_bw()
