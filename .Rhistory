shinyApp(ui, server)
submitButton("Update View", icon("refresh")),
helpText("When you click the button above, you should see",
"the output below update to reflect the value you",
"entered at the top:")
library(shiny)
library(tidyverse)
ui <- fluidPage(
textInput(inputId = "caption",
label="Caption",
value=3),
submitButton("Update View", icon("refresh")),
helpText("When you click the button above, you should see",
"the output below update to reflect the value you",
"entered at the top:"),
verbatimTextOutput("value"),
plotOutput("barplot")
)
server <- function(input, output) {
dat <- reactive({
data.frame(x=letters[1:input$caption], y=rnorm(n=input$caption))
})
output$barplot <- renderPlot({
dat() %>%
ggplot(aes(x=x, y=y)) +
geom_bar(stat="identity")
})
}
shinyApp(ui, server)
library(tidyverse)
library(rvest)
doc <- read_html("https://bioweb.bio/faunaweb/amphibiaweb/EspeciesEstadisticas/EndemicasOrden/Anura")
html_nodes(doc, xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[3]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
html_nodes(doc, "[class='ng-binding']") %>%
html_text()
doc %>%
html_nodes("[class='ng-binding']") %>%
html_text()
doc %>%
html_nodes("h2") %>%
html_text()
doc
doc %>%
html_nodes(css=".toctext") %>%
html_text()
doc %>%
html_nodes(xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[1]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
doc <- read_html("https://bioweb.bio/faunaweb/amphibiaweb/EspeciesEstadisticas/EndemicasOrden/Anura")
doc %>%
html_nodes(xpath="/html/body/div/div[2]/div/section/div[3]/article/div/div/div/div[1]/div[1]/div/div/div[2]/div[1]/div[1]/div[1]/a/h2/i") %>%
html_text()
doc %>%
html_element("h2")
starwars <- read_html("https://rvest.tidyverse.org/articles/starwars.html")
doc %>%
html_element("h2") %>%
html_text()
doc %>%
html_nodes("div.col-xs-12") %>%
html_text()
doc %>%
html_nodes("a.ng-scope") %>%
html_text()
library(AmphiNom)
aswSearch(query = "Bufo bufo")
aswSearch
install.packages("RSelenium")
library(RSelenium)
library(httr)
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"
# Query webpage
bbc <- GET("https://www.bbc.com/",
user_agent(ua))
# Confirm it's actually used the desired user agent
bbc$request$options$useragent
# Query webpage
bbc <- GET("https://amphibiansoftheworld.amnh.org/",
user_agent(ua))
# Confirm it's actually used the desired user agent
bbc$request$options$useragent
aswSearch
# Query webpage
bb <- GET("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent(ua))
# Confirm it's actually used the desired user agent
bb$request$options$useragent
bb
parse_rvest <- read_html("http://testing-ground.scraping.pro/",
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0")
library(rvest)
parse_rvest <- read_html("http://testing-ground.scraping.pro/",
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0")
parse_rvest <- read_html("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent = ua)
parse_rvest <- read_html("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",user_agent = ua)
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
x <- GET(url, add_headers('user-agent' = 'Gov employment data scraper ([[your email]])'))
x %>%
read_html()
ua
x <- GET(url, add_headers('user-agent' = ua))
x %>%
read_html()
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
# Query webpage
bb <- GET("https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo",
user_agent(ua))
bb
bb %>%
read_html()
#####
ua="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
x <- GET(url, add_headers('user-agent' = ua))
x %>%
read_html()
x <- GET(url, add_headers('user-agent' = ua),user_agent(ua))
x %>%
read_html()
library(RSelenium)
library(rvest)
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
remDr <- rD[["client"]]
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
remDr <- rD[["client"]]
remDr$navigate(fund_link)
remDr$switchToFrame(NULL)
fund_page = xml2::read_html(remDr$getPageSource()[[1]])
fund_page %>% read_html()
fund_link <- url
rD <- rsDriver(browser = 'firefox',port=4567L,verbose=F)
rD <- rsDriver(browser="firefox", port=4545L, verbose=F)
rD <- rsDriver(browser="firefox", port=4545L, verbose=T)
suppressWarnings(tryCatch(rm(remDr),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){}))
gc()
suppressWarnings(tryCatch(rm(remDr),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){}))
suppressWarnings(tryCatch(rD),error=function(e){})
rD <- rsDriver(browser="firefox", port=4545L, verbose=T)
rD1 <- rsDriver(browser = "chrome", port = 4567L, geckover = NULL,
chromever =  "latest", iedrver = NULL,
phantomver = NULL, extraCapabilities = cprof)
rD1 <- rsDriver(browser = "chrome", port = 4567L, geckover = NULL,
chromever =  "latest", iedrver = NULL,
phantomver = NULL)
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua))
url="https://stackoverflow.com/questions/64391812/scrape-site-that-asks-for-cookies-consent-with-rvest"
# Query webpage
bb <- GET(url,
user_agent(ua))
bb
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua))
bb
# Confirm it's actually used the desired user agent
bb$request$options$useragent
bb$request$options
bb$request
header="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers("header"=header))
bb$request
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers("Headers"=header))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
header=add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# set url
url="https://amphibiansoftheworld.amnh.org/Amphibia/Anura/Bufonidae/Bufo/Bufo-bufo"
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
# Let's set user agent to a super common one
ua <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0"
header="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
header=c("text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
"application/font-woff2;q=1.0,application/font-woff;q=0.9,*/*;q=0.8")
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header))
# Confirm it's actually used the desired user agent
bb$request
bb
# Query webpage
bb <- GET(url,
#user_agent(ua),
#add_headers(Accept=header),
#accept = "application/zip",
user_agent("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"))
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
#user_agent(ua),
#add_headers(Accept=header),
accept = "application/zip",
user_agent("Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"))
# Confirm it's actually used the desired user agent
bb$request
bb
# Confirm it's actually used the desired user agent
bb$request
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header),
httpget=F
)
# Confirm it's actually used the desired user agent
bb$request
header=c("text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8")
# Query webpage
bb <- GET(url,
user_agent(ua),
add_headers(Accept=header),
)
# Confirm it's actually used the desired user agent
bb$request
library(devtools)
install_github("hcliedtke/AmphiNom", build_vignettes = TRUE)
install_github("hcliedtke/AmphiNom", build_vignettes = FALSE)
setwd("~/Documents/upwork/richard_wheeler/ai_dashboards")
#### cf
devtools::install_github("hrbrmstr/cfhttr")
library(cfhttr)
res <- cf_GET(url)
install.packages(c("ade4", "ape", "aplot", "arules", "backports", "bayesplot", "betapart", "BH", "BiocManager", "blob", "blogdown", "bookdown", "boot", "brew", "brio", "brms", "Brobdingnag", "broom", "bslib", "cachem", "car", "carData", "caret", "checkmate", "class", "clipr", "cluster", "colorspace", "commonmark", "compositions", "conquer", "corHMM", "corpcor", "corrplot", "cpp11", "credentials", "crosstalk", "cubature", "dashboardthemes", "data.table", "DBI", "DEoptimR", "desc", "deSolve", "devtools", "diffobj", "distributional", "diversitree", "doMC", "doParallel", "doSNOW", "downlit", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "extrafont", "fable", "fabletools", "fastmatch", "fdrtool", "feasts", "fontawesome", "foreach", "forecast", "foreign", "formatR", "fs", "future", "future.apply", "gargle", "generics", "geometry", "gert", "GGally", "ggdist", "ggfun", "ggnewscale", "ggspectra", "gh", "gmp", "googledrive", "googlesheets4", "gprofiler2", "graphlayouts", "gtools", "haven", "highcharter", "hisse", "Hmisc", "hms", "htmlTable", "htmlwidgets", "httpuv", "hyperSpec", "igraph", "iterators", "jpeg", "kernlab", "KernSmooth", "klaR", "knitr", "lars", "later", "lattice", "lavaan", "leaflet", "lightr", "linprog", "lme4", "lmtest", "loo", "lubridate", "magic", "magick", "magrittr", "maps", "maptools", "MASS", "mathjaxr", "Matrix", "matrixStats", "mclust", "memoise", "mgcv", "misc3d", "MuMIn", "mvtnorm", "nlme", "nloptr", "nnet", "odbc", "openxlsx", "packrat", "pander", "parallelly", "pavo", "pbapply", "permute", "photobiology", "photobiologyWavebands", "phytools", "pkgbuild", "pkgdown", "pkgload", "plotly", "plotrix", "pls", "plyr", "polynom", "posterior", "processx", "progressr", "prospectr", "proxy", "psych", "qgraph", "quantreg", "R.utils", "ragg", "raster", "rattle", "rcdd", "rcmdcheck", "RColorBrewer", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "readr", "readxl", "recipes", "remotes", "reprex", "resemble", "reshape", "reticulate", "rex", "rgdal", "rgeos", "rio", "rjson", "rlist", "rmarkdown", "Rmpfr", "rncl", "RNeXML", "robustbase", "RODBC", "roxygen2", "rpart", "rprojroot", "rsconnect", "RSQLite", "rstan", "rstantools", "Rttf2pt1", "runner", "rvcheck", "rversions", "s2", "sass", "scales", "scholar", "segmented", "servr", "sessioninfo", "sf", "sfsmisc", "shiny", "shinydashboard", "shinyjs", "shinystan", "shinyWidgets", "simsalapar", "slam", "slider", "snow", "sp", "spam", "spatial", "styler", "subplex", "survival", "svglite", "systemfonts", "terra", "testthat", "textshaping", "tidybayes", "tidygraph", "tidyr", "tidyselect", "tidytree", "tinytex", "toOrdinal", "tsbox", "tseries", "tsibble", "tsibbledata", "TTR", "units", "usethis", "uuid", "vctrs", "vegan", "viridis", "visNetwork", "vroom", "waldo", "webshot", "withr", "wk", "xfun", "XML", "yaml", "zip", "zoo"))
# set working directory
setwd("~/Documents/git_projects/ADDA_taller2_2022/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse,gprofiler2)
res<-readRDS("./results/deseq2_results.rds")
res
View(res)
res
xtrop<-read_csv("./data/PCU23_annotations_xtr105.csv")
xtrop %>% head()
View(xtrop)
View(res)
res$bD_bV %>% head()
res$bD_bV %>%
as_tibble(rownames = "gene")
res$bD_bV %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05)
res$bD_bV %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
}
# now extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
summary(res$bD_bV, alpha=0.05)
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
filter(abs(log2FoldChange)>2) %>%
pull(gene)
)
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
filter(abs(log2FoldChange)>2) %>%
pull(gene)
)
}
# now extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
}
str(sig_deg)
str(xtrp)
str(xtrop)
xtrop %>% head()
str(sig_deg)
View(xtrop)
# apply function to list of Pelobates IDs
xtr_deg<-lapply(sig_deg, FUN=extract_xtr)
xtract_xtr<-function(x) {
return(
xtrop %>%
filter(gene_id %in% x) %>%
pull(xtr_pep_id_x) %>%
unique()
)
}
# apply function to list of Pelobates IDs
xtr_deg<-lapply(sig_deg, FUN=extract_xtr)
str(xtr_deg)
extract_xtr<-function(x) {
return(
xtrop %>%
filter(gene_id %in% x) %>%
pull(xtr_pep_id_x) %>%
unique()
)
}
# apply function to list of Pelobates IDs
xtr_deg<-lapply(sig_deg, FUN=extract_xtr)
str(xtr_deg)
str(sig_deg)
rownames(res$bD_bV)
lapply(res, FUN=nrow())
lapply(res, FUN=nrow
lapply(res, FUN=nrow)
lapply(res, FUN=nrow())
lapply(res, FUN=nrow
lapply(res, FUN=nrow)
lapply(X=res, FUN=nrow)
xtr_bg<-extract_xtr(rownames(res[[1]]))
str(xtr_bg)
####
sig_deg %>% head()
xtr_deg %>% head()
xtr_bg %>% head()
#
# set base url:
set_base_url("http://biit.cs.ut.ee/gprofiler")
# run the analysis
res_ora<-gost(multi_query = FALSE, # returns separate results tables for multiquery
custom_bg = xtr_bg, # our background
query=xtr_deg, # our list of gene sets
organism="xtropicalis", # the organism our annotations belong to
exclude_iea = FALSE, # include GO terms that were electronically assigned
correction_method = "gSCS", # the recommended multiple testing correction.
sources=c("GO:BP","GO:CC","GO:MF", "KEGG","REAC"), # the functional sets we are interested in
evcodes=FALSE, ## evcodes TRUE needed for downstream analysis like enrichment maps in Cytoscape, but this takes longer.
significant= FALSE) # return all terms, not just the significant ones
# the results are stored as a "results" dataframe
head(res_ora$result)
# the results are stored as a "results" dataframe
head(res_ora$result)
gostplot(res_ora)
res_ora$result %>% head()
res_ora$result %>% head()
res_ora$result %>%
select(query,term_name, p_value, intersection_size, query_size,source) %>%
filter(p_value<0.05) %>%
mutate(GeneRatio=intersection_size/query_size) %>% head()
mutate(term_name = factor(term_name, levels=unique(term_name))) %>%
ggplot(aes(x=GeneRatio, y=term_name)) +
geom_point(aes(color=p_value, size=intersection_size)) +
ylab("") +
scale_colour_viridis_c(direction = 1, option = "magma") +
facet_grid(source~query,scales = "free_y",space = "free") +
theme_bw()
arrange(GeneRatio) %>% head()
res_ora$result %>%
select(query,term_name, p_value, intersection_size, query_size,source) %>%
filter(p_value<0.05) %>%
mutate(GeneRatio=intersection_size/query_size) %>%
arrange(GeneRatio) %>% head()
res_ora$result %>%
select(query,term_name, p_value, intersection_size, query_size,source) %>%
filter(p_value<0.05) %>%
mutate(GeneRatio=intersection_size/query_size) %>%
arrange(GeneRatio) %>%
mutate(term_name = factor(term_name, levels=unique(term_name))) %>% head()
res_ora$result %>%
select(query,term_name, p_value, intersection_size, query_size,source) %>%
filter(p_value<0.05) %>%
mutate(GeneRatio=intersection_size/query_size) %>%
arrange(GeneRatio) %>%
mutate(term_name = factor(term_name, levels=unique(term_name))) %>%
ggplot(aes(x=GeneRatio, y=term_name)) +
geom_point(aes(color=p_value, size=intersection_size)) +
ylab("") +
scale_colour_viridis_c(direction = 1, option = "magma") +
facet_grid(source~query,scales = "free_y",space = "free") +
theme_bw()
###
library(plotly)
dat<-res$bD_bV
dat %>% head()
dat %>%
as.data.frame()
dat %>%
as.data.frame() %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj))) +
geom_point()
gg<-dat %>%
as.data.frame() %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj))) +
geom_point()
ggplotly(gg)
gg<-dat %>%
as.data.frame(row.names = "gene_id") %>% head()
gg<-dat %>%
as.data.frame(row.names = 1) %>% head()
gg
dat %>%
es_tibble(row.names = "gene") %>% head()
dat %>%
as_tibble(row.names = "gene") %>% head()
dat %>%
as_tibble(rownames =  "gene") %>% head()
ggplot(aes(x=log2FoldChange, y=-log10(padj),
text=gene)) +
geom_point()
gg<-dat %>%
as_tibble(rownames =  "gene") %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj),
text=gene)) +
geom_point()
gg
ggplotly(gg, tooltip = text)
ggplotly(gg, tooltip = "text")
gg<-dat %>%
as_tibble(rownames =  "gene") %>%
filter(padj<0.1) %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj),
text=gene)) +
geom_point()
ggplotly(gg, tooltip = "text")
ggplotly(
dat %>%
as_tibble(rownames =  "gene") %>%
filter(padj<0.1) %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj),
text=gene)) +
geom_point(),
tooltip = "text")
dat %>% head()
xtrop %>% head()
dat %>%
as_tibble(rownames =  "gene_id") %>%
left_join(xtrop) %>% head
dat %>%
as_tibble(rownames =  "gene_id") %>%
left_join(xtrop) %>% head()
ggplotly(
dat %>%
as_tibble(rownames =  "gene_id") %>%
left_join(xtrop) %>%
filter(padj<0.1) %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj),
text=pep_description)) +
geom_point(),
tooltip = "text")
