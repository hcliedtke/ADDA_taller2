---
title: "Differential Gene Expression"
subtitle: | 
  MADOBIS: Aplicaciones y Discusiones en Desarrollo Animal
author:
- name: "H. Christoph Liedtke"
  affiliation: "Estación Biológica de Doñana"
date: '2022-04-04'
output: webexercises::webexercises_default
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      #results = "hide",
                      eval = TRUE,
                      message=FALSE,
                      error=FALSE)
knitr::opts_knit$set(root.dir = '../')
library(webexercises)
```


#### Prepare environment

Set your working directory and load the libraries we will need.

```{r eval=TRUE}
# set working directory
setwd("~/Documents/git_projects/ADDA_taller2_2022/")

# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")

# use pacman to load libraries
pacman::p_load(tidyverse, DESeq2, apeglm)

```


## Background

In the 1st exercise, we explored the RNA-Seq count data from salmon. We saw that this data:

1. Has counts, abundances, lengths.
2. Comes from different experimental treatments (dark vs. light backgrounds)
3. Comes from different tissues (liver, dorsal skin, ventral skin)

The aim of this exercise is to go through a workflow for identifying genes that are significantly deferentially expressed when comparing two experimental treatments. We saw that the liver and skin samples were very different in their expression profiles. For this exercise, we will therefore only focus on the skin samples. This workflow entails the following general steps:

1. Import quantification data.
2. Perform a differential gene expression analysis using `DESeq2`.
3. Evaluate the quality of the results.
4. Summarize the results.

## Load data

We will start by loading the quantification data from `salmon` and the design matrix of the experiment, just like we did for the previous exercise

```{r eval=TRUE}
txi<-readRDS("./data/salmon_gene_counts.rds")
samples<-read_csv("./data/design_matrix.csv")
```

### Subset data

Because we only want to be working with one tissue (in this case skin), we want to filter out all of the remaining data from the design matrix and the expression data. To make things a little more convenient, we will also create a new variable (`condition`) which combines the `treatment` and `side` variable.

```{r}
samples <- samples %>%
  filter(tissue=="skin") %>%
  mutate(condition=as.factor(paste(treatment, side, sep="_")))

## filter txi matrices
txi$abundance<-txi$abundance[,samples$sample_id]
txi$counts<-txi$counts[,samples$sample_id]
txi$length<-txi$length[,samples$sample_id]
```

## Make a DESeqDataSet object

We can now combine the design matrix and the expression data into a format that DESeq2 likes. `tximport` plays very well with DESeq2, so this is easy!

```{r}
dds <- DESeqDataSetFromTximport(txi,
                         colData = samples,
                         design = ~ condition)

dds
```

The dataset should have successfully been stored as a `DESeqDataSet` object. You should see that it has imported the `counts` and the `length` data from the `txi` object and the sample information from the design matrix. lets take a look at this object:

```{r}
str(dds)
```

You may have seen this type of object before, but it most likely is not as common as other types.

> _Question:_ What is this kind of object? Is there anything you are unfamiliar with?

`r hide("Show Answer")`

It is an S4 object system. R has three object oriented systems: S3, S4 and R5. You can read up about them [here](http://adv-r.had.co.nz/OO-essentials.html). For now, you just need to know that most often you will work with S3 objects, which can be conveniently accessed with `$` for example. S4 objects are a little different. They usually have data stored in "slots" which are indicated with `@`.
`r unhide()`

Working with this type of object sometimes requires specific "accessor" functions (or methods) to get at data stored in 'slots'. For example, the `dds` object we created, has two assays: `counts` and `avgTxLength`. We can access them with the appropriately named functions, some specific, others more general: 

```{r}
counts(dds) %>% head() # uses counts() function to specifically extract the counts
assays(dds)[["avgTxLength"]] %>% head() # uses assays() function with typical indexing operators.
```

> _Question:_ What is different about this count data compared to the raw count data we imported?

`r hide("Show Answer")`

```{r}
head(counts(dds))
head(txi$counts)
```
The decimal counts have been rounded off to make them integers.
`r unhide()`


## Pre-filtering

You may have seen that in some workflows or examples, people filter out genes that have generally very low counts, or even filters whose counts don't vary very much across samples. In theory, this is not necessary with DESeq2 as it will handle this on the fly (read more [here](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#pre-filtering)), but reducing the size of the matrix can greatly speeding up downstream calculations and reduce the memory requirements. 

As we saw in the previous exercise, there are many liver-specific genes that most likely are not deferentially expressed in skin. There are therefore many rows of genes with 0 or very low counts. We can at least remove those:

```{r}
# keep only rows with with counts summing up to 10 or more
dds <- dds[rowSums(counts(dds)) >= 10,]
```

## Sample clustering

In the previous exercise, we learned that a sample PCA is a good way of checking to see if the biological replicates per treatment cluster together. We did this on the normalized counts (the abundance, or TPM matrix). We can do the same, but using a "variance stabilized transformation" (VST) of the count data, which is slightly more appropriate because it normalizes across samples, not within samples, and takes other factors into consideration, such as the length of the target gene/transcript (more on that later), and the experimental design.

```{r}
vst_counts <- vst(dds, blind=F)
# be sure to set `blind=F` to avoid overly shrinking the data (blind=T will not incorporate experimental design and so 'treatment' effects would be treated as noise)
```

Now we can use a `canned` function to run a PCA and plot the first two components:

```{r}
plotPCA(vst_counts,
        intgroup=c("side", "treatment"), # indicate how to label the points
        returnData=F, # plot only
        ntop=500) # use only 500 most variable genes.
```

> _Question:_ What can we say from this initial exploration of the transformed counts?

`r hide("Show Answer")`

* We see some clustering of biological replicates, though perhaps not to the extend we expected. Should we be worried about this? 
* The first component is separating the dorsal from ventral skin, not the black from white skin. Is that surprising?

## Differential Expression Analysis

The ultimate goal of running such an analysis is to see if a given gene is expressed to a different degree in one condition vs. another condition. This sounds almost like a T-test kind of problem, but things are not that simple. In this exercise, I don't want to focus too much on the theory, but it might be worthwhile to refresh ourselfs what some of the "problematic" freatures of the data are:

* Many counts are low, or even zero.
* RNAseq data tends to exhibit overdispersion: the variance is much greater than the mean.
* The target contigs (e.g. genes) are of different lengths. You would expect longer contigs to also have more mapped reads.
* Each library (sample) consists of a different total number of reads.
* RNAseq experiments tend to have few (usually three) replicates per condition.
* There are typically thousands of genes, which means you are repeating the same pairwise test thousands of times.
* Highly expressed genes tend to 'eat up' more reads during sequencing, meaning that genes that are less expressed tend to be underrepresented. This means changes in expression in highly expressed genes are easier to detect than changes in genes that are expressed at lower levels.
  
The differential expression analysis in `DESeq2` takes several steps to try to deal with these problems. At its core it fits generalized linear models with a negative binomial distribution to each gene. It takes into account the estimated counts per gene, normalized by library size, but also takes into account the size of the target genes/transcripts and calculates a dispersion parameter, which tells you about how far the observed count is from the mean counts estimated by the model.
  
It then performs a pairwise comparison of the level of expression per gene in condition A vs. condition B. It uses the models per gene to estimate coefficients and standard error for each sample group (i.e. for  condition A and condition B). These coefficients are the estimates of log2 fold change. 
  
To test whether this log2 fold change for a given gene is significant, it then applies a statistical test (Wald test), to test the hypothesis that the parameter (log 2 fold change) is significantly different from 0. A multiple test correction is then applied, by default a version of the Benjamini-Hochberg False Discovery Rate (FDR). This is done by ranking the genes by p-value, then:
  
$adjusted\ p\ value = p\ value * \frac{total\ number\ of\ tests}{rank}$
  
In short, `DESeq2` does the following:

1. Estimation of size factors (for normalize counts)
2. Estimation of dispersion (e.g. for problem of large within-group variability and low sample sizes)
3. Negative binomial GLM fitting (good for modeling discrete counts with over-dispersion)
4. Wald statistics calculation and multiple testing correction (statistical significance testing)

These are all done with a single convenient function:

```{r}
dds <- DESeq(dds)
dds
```

> _Note: it looks like we are "overwriting" the `dds` object, but really, we are just adding more inforamtion to it_

This incredibly convenient function has done all of the heavy lifting for us, and it has even run some pair-wise tests already, based on the `~condtion` variable we set.  

We can access the names of the pairwise tests like so:

```{r}
resultsNames(dds)
```

> _Question:_ Is there anything unexpected about the list of pair-wise tests?

`r hide("Show Answer")`
We had 4 treatment levels, which should result in a total of 6 pairwise comparisons. But here, there are only 3.
   
This is because DESeq2 compares everything to a baseline condition. If this is not specified, it will use the first alphabetic factor level, which in this case is "black_dorsal". As a result only xxx_vs_black_dorsal comparisons are made.

This is an important detail to remember: **the second factor is always considered to be the "base level" or "control" variable.**

`r unhide()`

## Examining differential expression analysis results 

We can extract the results for the pair-wise tests from the `dds` object like so:

```{r}
res<-results(dds)
res
```

If we don't specify anything else, it will extract just the first comparison. In this case "white ventral vs black dorsal". This table has the following information:

1. Rows are genes.
2. Per gene, there are 6 metrics:
  * baseMean: mean of normalized counts for all samples
  * log2FoldChange: The effect size estimate. This value indicates how much the gene or transcript's expression seems to have changed between the comparison and control groups. This value is reported on a logarithmic scale to base 2.
  * lfcSE: The standard error estimate for the log2 fold change estimate
  * stat: The value of the test statistic for the gene or transcript.
  * pvalue: P-value of the test for the gene or transcript.
  * padj: Adjusted P-value for multiple testing for the gene or transcript.

> _Question:_ Is there anything unexpected about the adjusted p-values?

`r hide("Show Answer")`
Some of the adjusted p-values are `NA`. This is what the `DESeq2` handbook tells us:

"If a row is filtered by automatic independent filtering, for having a low mean normalized count, then only the adjusted p value will be set to NA. Description and customization of independent filtering is described below".

Let's check some of those counts with `NA` padj:

```{r}
counts(dds)[rownames(res)[is.na(res$padj)],] %>% head(15)
```

Indeed! all have very low counts!! they are therefore unreliable, and should rightfully not be included in the results.
`r unhide()`

We could also extract results of specific comparisons. there are two ways to do this:

```{r}
# 1. using the result names:
results(dds, name="condition_white_dorsal_vs_black_dorsal")
# 2. using contrasts:
results(dds, contrast=c("condition","white_dorsal","black_dorsal"))
```

These two approaches should be largely the same (though baselines are treated slightly differently), but the second has some advantages. Namely, you can change the factor order (in our case, there is not really a clear control/treatment, right?), and, you can calculate results using different baseline than was included in the original, automatize run. lets make four results objects, comparing the dorsal and ventral skins within each treatment, and the dorsal skins across treatments:

```{r}
# white dorsal vs white ventral
res_wD_wV<-results(dds, contrast=c("condition","white_dorsal","white_ventral"))
# black dorsal vs black ventral
res_bD_bV<-results(dds, contrast=c("condition","black_dorsal","black_ventral"))
# black dorsal vs white dorsal
res_bD_wD<-results(dds, contrast=c("condition","black_dorsal","white_dorsal"))
# black ventral vs white ventral
res_bV_wV<-results(dds, contrast=c("condition","black_ventral","white_ventral"))
```

We now have four of the same types of objects and we will do the same kinds of things with these objects down the line. It is therefore 'good coding' to save these all in a single list object so we can use `apply()` for loops to do the same thing to each object:

```{r}
res<-list(bD_bV = res_bD_bV,
          wD_wV = res_wD_wV,
          bV_wV = res_bV_wV,
          bD_wD = res_bD_wD)
```


We can now summarize these results tables:

```{r}
# single comparison, here using a padj cutoff of 0.05
summary(res_bD_bV, alpha=0.05)
# for all comparisons:
lapply(res, summary, alpha=0.05)
```

This returns the number of up-regulated genes (LFC>0) and down-regulated genes (LFC<0) with respect to the control variable. Other information is also given, such as the number of outliers and low counts. 

> _Question:_ What do you notice about these results? Do they meet your expectations from the PCA earlier?

`r hide("Show Answer")`

It seems like the dorsal vs. ventral comparisons are producing many more up and down regulated genes than the black vs. white comparison. We should have expected this, given the PCA. This indicates that not all skin is the same! At the level of gene expression, the change in pigmentation on the dorsum is minimal compared to the difference in gene expression between dorsal and ventral skin of much similar colour!
`r unhide()`

At this point, we can do some quality checks, to make sure that all of the steps that `DESeq2 `has done, worked as expected. For example:

### P-value distributions

The over-dispersion correction should result that there is an even distribution of p-values, with an "enrichment" of genes with low p-values (i.e. a rectangular plot with a peak near 0).

```{r}
# single plot:
hist(res_bD_bV$pvalue, breaks=50, col="grey", main="")

# for all comparisons:
par(mfrow=c(2,2))
par(mar=c(4,4,1,1))
for(i in names(res)){
  hist(res[[i]]$pvalue, breaks=50, col="grey", main=i, xlab = "p-value")
}
par(mfrow=c(1,1))
```

All-in-all, not bad. In all cases, we see the expected "enrichment" of genes with low p-values and then a relatively uniform/rectangular distribution for all other p-values. It is not perfect, and there is a little bit of a hill-shape with higher p-values. IF this were more extreme (both hill-shaped or  U-shaped distributions) you may want to try to remove outliers or fit models with more than one dispersion parameter (see [here](https://www.huber.embl.de/users/klaus/Teaching/DESeq2Predoc2014.html) for example, or look up [local dispersion](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#local-or-mean-dispersion-fit), in the DESeq2 handbook).

### Dispersion plots

To accurately model sequencing counts, we need to generate accurate estimates of within-group variation (variation between biological replicates of the same treatment/condition group) for each gene. With only a few (usually 3) replicates per group, the estimates of variation for each gene are often unreliable (due to the large differences in dispersion for genes with similar means).

To address this problem, DESeq2 shares information across genes to generate more accurate estimates of variation based on the mean expression level of the gene using a method called ‘shrinkage’. DESeq2 assumes that genes with similar expression levels have similar dispersion.
  
Estimating the dispersion for each gene separately:
  
To model the dispersion based on expression level (mean counts of replicates), the dispersion for each gene is estimated using maximum likelihood estimation. In other words, given the count values of the replicates, the most likely estimate of dispersion is calculated.
  
We can easily plot these dispersion estimates.
  
```{r}
plotDispEsts(dds)
```

* The red dots are the expected dispersion of each gene, given the size of the count, that is estimated by the model.
* The black dots are the normalized expression levels (counts) and estimated dispersion for each gene.
* The blue points are the same genes, but 'shrunk' towards the values predicted by the model (the red line). Genes that were not shrunk are outlined in blue

> _Question:_ What are some interesting things to note about this plot?

`r hide("Show Answer")`

* The "final" count estimates (in blue) are closer to the red, fitted line (the model estimates) than the original gene counts. I.e. the dispersion correction is working as expected.
* Genes with low counts have higher dispersion, but this curve flattens out.
* Genes that have much higher dispersion than expected are identified as outliers (black dot with blue circles). These are NOT "shrunk". This is due to the likelihood that the gene does not follow the modeling assumptions and has higher variability than others for biological or technical reasons. Shrinking these could result in the detection of false positives.
`r unhide()`

All-in-all it looks good!

> _Question:_ Why is there only 1 plot, but for the p-value distributions there was one for each comparison?

`r hide("Show Answer")`
Only a single binomial model is fitted to each gene, i.e. there is only a single dispersion estiamte and mean normalized count across all samples per gene.
`r unhide()`

## Exploring log2 fold changes

The typical plot to show the distribution of differentially expressed genes, is a "MA-plot". Here, we plot the mean of normalized counts again, but this time against the log fold change:

```{r}
# single plot
DESeq2::plotMA(res_bD_bV)

# all comparisons (with lapply)
par(mfrow=c(2,2)) # divide plot area in 4
lapply(names(res),function(i) DESeq2::plotMA(res[[i]], main=i, alpha=0.05))
par(mfrow=c(1,1))
```


> _Question:_ What can we say from these plots?

`r hide("Show Answer")`
* The same as from the summary() function:
  * Dorsal-ventral comparisons result in more differentially expressed genes (DEGs), than black-white comparisons?
  * DEGs are more or less evenly up (positive fold changes) and down (negative fold changes) regulated for each comparison
* There is a lot of noise for genes with genes with low normalized counts. The fold changes are *not* shrunk.
`r unhide()`

### Shrinkage

The DESeq2 package incorporates a prior on log2 fold changes, resulting in moderated estimates from genes with low counts and highly variable counts, as can be seen by the narrowing of spread of points on the left side of the plot. This is called "shrinkage" and is done to avoid that these values, which otherwise would frequently be unrealistically large, dominate the top-ranked log fold changes.

A useful exercise to reduce the noise of the low-count genes is therefore to apply a shrinkage method. The most widely used type is the `apglm` method.

```{r}
# apeglm shrinkage can only be done on already calculated coefficients:
resultsNames(dds)

# without shrinkage:
bD_bV_res<-results(dds,
                   name="condition_white_ventral_vs_black_dorsal")

bD_bV_res

# with shrinkage
bD_bV_shr<-lfcShrink(dds,
                   coef="condition_white_ventral_vs_black_dorsal",
                   type="apeglm")
bD_bV_shr
```

This produces the same type of "results" object, but you should notice that the first object shows the maximum likelihood estimates (MLE) of the fold change, whereas the second shows the shrunk (MAP) fold changes.

> _Question:_ How do the fold changes and adjusted p-values compare?
`r hide("Show Answer")`

```{r}
par(mfrow=c(1,2))
par(mar=c(4,4,1,1))
# p values
plot(bD_bV_res$padj~bD_bV_shr$padj,
     xlab="adjusted p-value (shrunk)",
     ylab="adjusted p-value (MLE)")
# fold changes
plot(bD_bV_res$log2FoldChange~bD_bV_shr$log2FoldChange,
     xlab="Fold Change (shrunk)",
     ylab="Fold Change (MLE)")
par(mfrow=c(1,1))
```

* The p-values do not change! The number of significantly DEGs is therefore not affected by shrinkage
* intermediate absolute fold changes are similar, but genes whose fold changes are very large, are pulled towards 0 with the shrinkage.
`r unhide()`

The differences become very clear when repeating the MA-plot

```{r}
par(mfrow=c(1,2))
par(mar=c(4,4,4,1))
DESeq2::plotMA(bD_bV_res, main="MLE")
DESeq2::plotMA(bD_bV_shr, main="MAP")
```

Very often you will see the shrinkage versions of MA-plots, simply because they allow for a more pleasing visualization of the significant genes.  

Shrinkage can also be useful if you wish to rank genes based on their effect sizes.

## Exporting data

We have now finished the differential gene expression analysis. As the final step, we should export our results. We can export the individual results tables as .csv files, and we can export the various objects, in case we want to process them down the road

```{r}
# make a results folder if it does not yet exist
dir.create("results", showWarnings = FALSE)

# export individual results tables
for(i in names(res)){
  write.csv(as.data.frame(res[[i]]), paste0("./results/deseq2_", i,".csv"))
}
# export .rds files
saveRDS(res, "./results/deseq2_results.rds")
saveRDS(dds, "./results/deseq2_dds.rds")
```

